% -----------------------------------------------
% Template for ICMC SMC 2014
% adapted and corrected from the template for SMC 2013,  which was adapted from that of  SMC 2012, which was adapted from that of SMC 2011
% -----------------------------------------------

\documentclass{article}
\usepackage{icmcsmc2014}
\usepackage{xcolor}
\usepackage{times}
\usepackage{ifpdf}
\usepackage[english]{babel}
%\usepackage{cite}

%%%%%%%%%%%%%%%%%%%%%%%% Some useful packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% See related documentation %%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{amsmath} % popular packages from Am. Math. Soc. Please use the 
%\usepackage{amssymb} % related math environments (split, subequation, cases,
%\usepackage{amsfonts}% multline, etc.)
%\usepackage{bm}      % Bold Math package, defines the command \bf{}
%\usepackage{paralist}% extended list environments
%%subfig.sty is the modern replacement for subfigure.sty. However, subfig.sty 
%%requires and automatically loads caption.sty which overrides class handling 
%%of captions. To prevent this problem, preload caption.sty with caption=false 
%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}


%user defined variables
\def\papertitle{Towards a Music Source Wiki}
\def\firstauthor{Mike Solomon}
\def\secondauthor{Mika Kuuskankare}
\def\thirdauthor{Dominique Fober}
\def\fourthauthor{Vesa Norilo}

% adds the automatic
% Saves a lot of ouptut space in PDF... after conversion with the distiller
% Delete if you cannot get PS fonts working on your system.

% pdf-tex settings: detect automatically if run by latex or pdflatex
\newif\ifpdf
\ifx\pdfoutput\relax
\else
   \ifcase\pdfoutput
      \pdffalse
   \else
      \pdftrue
\fi

\ifpdf % compiling with pdflatex
  \usepackage[pdftex,
    pdftitle={\papertitle},
    pdfauthor={\firstauthor, \secondauthor, \thirdauthor},
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen; 
                     % especially useful if working with a big screen :-)
   ]{hyperref}
  %\pdfcompresslevel=9

  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are and their extensions so 
  %you won't have to specify these with every instance of \includegraphics
  \graphicspath{{./figures/}}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}

  \usepackage[figure,table]{hypcap}

\else % compiling with latex
  \usepackage[dvips,
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen
  ]{hyperref}  % hyperrefs are active in the pdf file after conversion

  \usepackage[dvips]{epsfig,graphicx}
  % declare the path(s) where your graphic files are and their extensions so 
  %you won't have to specify these with every instance of \includegraphics
  \graphicspath{{./figures/}}
  \DeclareGraphicsExtensions{.eps}

  \usepackage[figure,table]{hypcap}
\fi

%setup the hyperref package - make the links black without a surrounding frame
\hypersetup{
    colorlinks,%
    citecolor=black,%
    filecolor=black,%
    linkcolor=black,%
    urlcolor=black
}


% Title.
% ------
\title{\papertitle}

% Authors
% Please note that submissions are NOT anonymous, therefore 
% authors' names have to be VISIBLE in your manuscript. 
%
% Single address
% To use with only one author or several with the same address
% ---------------
%\oneauthor
%   {\firstauthor} {Affiliation1 \\ %
%     {\tt \href{mailto:author1@smcnetwork.org}{author1@smcnetwork.org}}}

%Two addresses
%--------------
% \twoauthors
%   {\firstauthor} {Affiliation1 \\ %
%     {\tt \href{mailto:author1@smcnetwork.org}{author1@smcnetwork.org}}}
%   {\secondauthor} {Affiliation2 \\ %
%     {\tt \href{mailto:author2@smcnetwork.org}{author2@smcnetwork.org}}}

% Four addresses
% --------------
 \threeauthors
   {\firstauthor} {Grame \\ %
     {\tt \href{mailto:mike@mikesolomon.org}{mike@mikesolomon.org}}}
   {\secondauthor} {Sibelius Academy \\ %
     {\tt \href{mailto:mkuuskan@siba.fi}{mkuuskan@siba.fi}}}
   {\thirdauthor} {Grame \\ %
     {\tt \href{mailto:fober@grame.fr}{fober@grame.fr}}}
%   {\fourthauthor} {Sibelius Academy \\ %
%     {\tt \href{mailto:vnorilo@gmail.com}{vnorilo@gmail.com}}}
\usepackage{mdframed}
\mdfdefinestyle{objectivestyle}{% 
linecolor=black,linewidth=1pt,% 
frametitlerule=true,% 
frametitlebackgroundcolor=gray!20,
innertopmargin=\topskip,
skipabove=5pt,
skipbelow=5pt
}

\mdtheorem[style=objectivestyle]{objective}{Objective}
% ***************************************** the document starts here ***************
\begin{document}
%
\capstartfalse
\maketitle
\capstarttrue
%
\begin{abstract}
The Music Source Wiki project aims to create a wiki for the collective
editing, visualization and auralization of musical-source documents on
the web. It will do so by developing a robust music representation language
that describes several music phenomena (notation, audio, processes) through
a small axiomatic language. A web API will be created to transmit this
language between terminals, and a wiki-like website will allow for the
realtime editing and just-in-time compilation of musical source documents.
The present paper presents the basic objectives of the project as well as
three major phases into which the research and development will be divided.
The project is a joint endeavor between researchers
affiliated with the Grame (Lyon) and the Sibelius Academy (Finland).
\end{abstract}
%

\section{Introduction}\label{sec:introduction}
The Music Source Wiki (MSW) project unites the fields of computer science, software
engineering and music in order to solve longstanding problems about music’s
representation on a computer as well as its ability to be distributed across
multiple computers. To frame the problem, we consider the representation of
music in state-of-the-art real\-time and non-real\-time music notation
environments.

Realtime environments, such as MuseScore~\cite{musescore}, concentrate on
the direct manipulation of graphical objects such as sound, waveforms,
graphics and video, often using approximations of complex structures in
order to facilitate quick rendering. Non-real\-time score editors, such as
Lilypond~\cite{lilypond06}, allow for robust musical representations at the expense of
interactivity. We see this disparity of music representation in real\-time and
non-real\-time environments as a fundamental problem in the field. Rich music
representation and real\-time interactivity should not be a trade-off –
instead, the two should complement each other.

The hampering effects of this issue are easily seen when one looks at how
other fields have solved the real\-time/non-real\-time problem. Online text
editors, for example, allow people to develop documents in real\-time while
retaining a rich view of these documents. The same is true of photo editing
on mobile devices, where users can apply filters to their photos almost
instantly thanks to automatic uploads and downloads to and from central
servers. We imagine a world where the same is possible in music – where,
thanks to a robust theoretical framework for the representation of music
transmitted to powerful servers over the web, users can work with rich
representations of music in real\-time.

This paper offers a practical roadmap
of the MSW project. The project seeks to provide an online music-source
wiki-inspired platform that lets multiple users edit and visualize
musical documents in realtime. After surveying the
state-of-the-art and describing the objectives of the project,
it discusses the three major phases of research necessary
for the implementation of a music-source wiki: (1) the creation of a robust
music representation language; (2) the elaboration of open web
specifications for the transmission of this language; and (3) the
construction of a collaborative on-line music editing platform.
\section{State-of-the-art}\label{sec:state-of-the-art}

All computer-assisted music notation programs are based on languages for the
representation of music that are more or less exposed to users. While it is
difficult to know the nature of the representation in closed-source
paradigms, open-source editors use music representation languages based on a
wide range of assumptions about how notated music should be encoded. Certain
formats, such as MusicXML~\cite{good2001musicxml}, use the instrument as the fundamental unit,
ascribing events to instruments and qualities to events in a hierarchical
manner. The language of the SCORE program focuses more on the physical
placement of musical glyphs. Yet others, like the LilyPond~\cite{lilypond06} and
Guido~\cite{hoos98}
languages, provide human-readable formats where notes, articulations,
dynamics, and rhythms are specified by their names in a given language. Some
paradigms, like that of MuseScore, offer no user-accessible textual representation
of music, translating a user’s point-and-clicks into internal objects that
represent musical symbols.

At present, there are a large number of score editors for desktop computers.
The two \emph{de facto} industry standard notation programs are Finale and
Sibelius. The most notable free software projects are LilyPond and
Guido. Both of these programs compile documents written in LATEX like
markup languages that are used to describe the contents of a musical score
in textual form. WYSIWYG interfaces for these programs, such as Denemo
(LilyPond) and GuidoEditor (Guido), provide a point-and-click interface that
is translated into markup language before being compiled. Additionally,
there are several lightweight notation editors, such as abc and Gscore, for
typesetting relatively simple notation. Finally, NoteAbility provides
another paradigm where the software functions like an advanced image editor
with music-notation specific functionalities.

Recently, web-viewable score editors have started to emerge. There are three
main online musical score editors: Noteflight, Melodus and Scorio.
Noteflight and Melodus seek to provide a full-featured music editing
platform online, similar to Google Documents’ role in the world of office
suites. Scorio is a hybrid tool that mixes rudimentary layout via a mobile
editing platform with publication-quality layout via JIT compilation through
LilyPond when possible. Several music tools, such as Sibelius, MuseScore,
Maestro, and Capriccio, offer online services where scores composed using
this software can be uploaded, browsed, and downloaded online. WebLily,
LilyBin, and OMET are all JIT compilation services that run the LilyPond
executable to compile uploaded code and return embedded SVG, canvas or PDF
visualizations depending on the tool. Lastly, scoreSVG is another
alternative based on the Scalable Vector Graphics, a language for describing
two-\-di\-men\-sion\-al vector graphics in XML.

Incorporating recording, synthesis and digital signal processing is a recent
phenomena in the pantheon of notation software.  The majority of approaches
follow one of two organizational principles:
\begin{enumerate}
\item A notation plugin is used to send control data to DSP objects.
\item Audio is linked to staves that are visualized in a score editor.
\end{enumerate}
The former solution does not provide publication-quality typesetting,
whereas the latter has a limited number of DSP options and little
integration with the notation engine.

The disparity between realtime and non-realtime performance is perhaps most
noticeable in music notation programs. Because line-breaking algorithms for
musical scores are $O(2^n)$ hard without using any predictive heuristics, the
addition of new measures and new instruments in realtime can quickly lead to
less graceful and/or more sluggish line breaking choices. Non-realtime
editors require a much longer compilation time for line breaks but almost
always achieve aesthetically satisfactory results.



\section{Objectives}\label{sec:objectives}
The objectives of the MSW project look to solve several of the problems
discussed in the introduction and that remain unsolved in the
state-of-the-art. While its final form will be a wiki-like platform enabling
remote collaboration on musical documents, the various steps building up to
this platform will result in numerous theoretical and technological advances
in music representation and music's transmission over the web.

The fundamental theoretical impediment that has hindered the development of
such a platform is the lack of a robust music representation language.
Encapsulating practices in diverse fields such as music education, music
information retrieval, music composition, computational musicology,
acoustics, digital signal processing, and performance requires versatile representations, flexible
visualizations, interactivity, accessibility of data, and musical knowledge
encoded into the system. Currently, there is no general purpose piece of
software that works equally well for all the aforementioned fields in
addition to being a high-quality typesetting tool. This is not for lack of
sufficient technological know-how, but rather a more fundamental problem of
a lack of a music representation language that can unite multiple musical
domains. These observations lead to the first objective of the MSW project.
\begin{objective}
Develop a music representation language that allows for the articulation of multiple
existent conventions in musical notation and sound, the invention of new
conventions, and the realization of these conventions in realtime and
non-realtime environments at various levels of refinement, including
publication-quality scores and concert-quality sound.
\end{objective}
Taking the need for robust computer-based music representations as a
starting point, this project looks to consider that need in light of
state-of-the-art trends in computing. It is undeniable that the majority of
software development is going into the cloud and that music technology is
becoming more democratized, with music’s creation and performance happening
increasingly by means of laptops and tablets. We believe, then, that a
state-of-the-art sound and music computing environment based on rich music
representation must allow for cloud computing. It should allow users to
create and communicate using open web protocols and standards and platform-independent
technologies. Decisions about what processes and data can be offloaded to a
central server, how data can be compressed, how users can collaborate on a
common project, and how the sharing and forking of musical projects takes
place should be encoded in the music representation language itself and
transmittable via web protocols. This leads to the second objective of the
project.
\begin{objective}
Create open web standards for the communication of musical
information between clients and a server, allowing for the distributed
processing and storage of musical data.
\end{objective}
Once a robust music representation is in place that can be communicated via
open web standards, several forms of music collaboration will be easier to
undertake. While there are many domains in which this could be relevant
(computer-assisted composition, live digital signal processing), the goal of
this project is to build a wiki-like music-source platform upon
these technologies.  
\begin{objective}
Construct a music-source wiki that allows musical scores, sound, and
processes to be collaboratively articulated and maintained.
\end{objective}
The objective of this platform is to fill a gap in
current on-line music sharing services. While there are several services
that allow for the sharing of finalized music scores and recordings (SoundCloud,
IMSLP), there are no current platforms dedicated to collaborating on
the sources of musical scores, audio, performances and analyses in real time.
Furthermore,
no projects allow for the forking of musical data \emph{\`a la} github, nor
do any projects allow for complete outputs in multiple formats as Faust does
for digital signal processing.  Once this platform exists, a wealth of
collaborative projects will be possible such as crowd-sourced critical
editions, real analysis involving several remote collaborators, etc.. By
relying on the computation power of a central server, it will allow for
realtime collaboration that benefits from the precision achieved in
non-realtime environments.
\section{Music representation}\label{sec:music-representation}
The project will start with a theoretical inquiry into the representation of
music, using multiple existing representational languages as starting points
to frame questions such as:
\begin{itemize}
\item Using Hoare's work on axiomatic approaches to
programming~\cite{hoare1969axiomatic} as a basis, what are the atomic units
with which musical sound, ideas, procedures and data can be represented?
\item In what ways can these units be combined to form
larger structures?
\item To what extent are these structures combinable and transmutable into
other exchange formats?
\end{itemize}

The methodology used to answer these questions will start with a survey of
existing music representations, resulting in the creation and publication of
a comprehensive literature review that covers: (1) major computer-music
encoding
formats~\cite{hoos98}~\cite{lilypond06}~\cite{good2001musicxml}~\cite{alvaro2010musicjson}~\cite{roland2002music},
(2) traditional representations and encodings of music,
including various notation systems~\cite{hultberg2000printed} and formalizations
of sound synthesis and treatment
methods~\cite{mason1953feedback}~\cite{foote1999visualizing},
and (3) theoretical texts on music representation, from
early theories like Rameau's treatises on figured bass~\cite{rameau:1722} to later works
like Schenker’s reductive analysis methods~\cite{schenker:1935}.

During this phase, special attention will be given to the transversality of
our music representation language.  Various phenomena, such as notation,
performance practice, musical algorithms and processes, sound synthesis and
signal processing will all have to be articulated via a combination of
atomic elements in this music representation.  Furthermore, we will need to
elaborate structures that allow for the linking of these elements.
This idea is partially implemented in visual programming environments like Max/MSP, where notation
structures can drive digital signal processing and vice-versa. Our project
seeks to generalize this to multiple aspects of music representation, control and
computation. For example, links between notation and process can control choices regarding
real\-time versus non-real\-time execution so that computation is reactive with
respect to content.

From these observations, a music representation language will be elaborated
along the following theoretical guidelines: (1) the theory of
representational language creation \cite{wagner2002design}~\cite{shieber1984design},
(2) the theory of process and algorithm
formalization~\cite{salwicki1970formalized}, and
(3) the theory of transcribing and storing language via exchange
formats~\cite{qiu1999programming}~\cite{gruber1993translation}. The
results of this research will be published as a technical report, offering a
complete grammar and alphabet for music representation as well as rules for
building a vocabulary. Several case studies will show how the language can
encode important musical works and concepts.

\section{Web-music specification}\label{sec:web-music-specification}
After having formalized a music representation language, we will turn to the
objective of creating a web music specification that allows this language to be
expressed across multiple terminals interacting with a server via a cloud
architecture. The open web specifications used to transmit the codified format
of our abstract musical representation will be created using a methodology
similar to that created for the Guido web API~\cite{solomon:2014}.
In the Guido web API, a Representational State Transfer (REST) server architecture
style~\cite{Fielding00}~\cite{richardson2008restful} is used to translate an Application
Programming Interface (API) into Uniform Resource Identifiers (URIs) via a
set of mapping conventions.

The same process of translation will be used in the
creation of open web specifications for our abstract musical representation,
extending these specifications to describe musical sound and processes. To verify
the portability of these specifications, they will be parallelly
developed in several common web interchange formats (JSON, XML, URIs, etc.),
aiming to achieve the same representational elegance and simplicity in all
of these formats. The result of this research will be a published open
specification as well as a series of libraries in common web languages
(JavaScript, PHP, etc.) to facilitate exchange via these specifications. The
specification will be empirically validated via a series of regression tests that
verify the transferring of every element of the abstract musical
representation over the web and the effective encoding, decoding and
translation of these test results into several programming languages and
open standard formats.


\section{Collaborative music editing platform}\label{sec:collaborative-music-editing-platform}
The Music Source Wiki (MSW) will be a nexus where
musicians can work collaboratively on musical projects. It consists in three
sub-parts -- a central server for data storage and processing, an online
music source editor, and an online music source visualizer.
\subsection{Server}
The MSW server will store all musical data in the music representation format
discussed in Section \ref{sec:music-representation}, receiving and sending
information using the web standards discussed in Section
\ref{sec:web-music-specification}.  Its ambition is to be able to input and
output as many common music exchange formats as possible, both proprietary and
non-proprietary, so that users can always work in formats with which they are
comfortable.  This means that multiple conversion scripts will need to be
implemented to translate formats into and out of our music representation
language.  Regression tests will verify lossless translation in several
formats.
\subsection{Source editor}
The MSW score editor will be an on-line web editor offering both a
markup-language format like LilyPond and a WYSIWYG format like MuseScore.
It will allow for the specification of musical information as well as the
use of global style sheets for the formatting of that information.  Depending
on the scope of the source and the modifications being made to it, the
server will make reactive decisions about when to update compilation, how
much to compile and the level of approximations that documents should have,
caching fully-compiled versions frequently.
\subsection{Source visualizer}
The ambition of the MSW project is to have a visualizer showing the results
of the source that synchronizes as fast as possible with the source editor.
This can be seen independently of the editor or concurrently with it. The
source visualizer will have filters that allow users to only access
data (notation, sound, metadata, comments, etc.). Like most WikiMedia sites,
discussion and log pages will accompany every project.
\section{Conclusion}\label{sec:conclusion}
The MSW initiative reunites three research axes into one project:
\begin{itemize}
\item The elaboration of a robust musical representation language.
\item The creation of open web standards for the transmission of this
language.
\item The construction of a music source wiki based on this representation
language that is transmitted via the open protocols.
\end{itemize}
The project brings together several researchers affiliated with the Grame
and Sibelius Academy.  Its provisional timetable is elaborated in Table
\ref{tab:timeline}.
\begin{table}[h]
\begin{center}
\begin{tabular}{|l|p{6cm}|}\hline
2016 & Publication of a technical report with the music representation
language. \\\hline
2017 & Publication of an open web specification for the transmission of this
language. \\\hline
2019 & Launch of the MSW website. \\\hline
\end{tabular}
\end{center}
 \caption{A provisional timeline for the MSW project.}
 \label{tab:timeline}
\end{table}
This paper surveys the major themes united in this project in hopes of
widening the community of researchers participating in its development.
\begin{acknowledgments}
The authors would like to thank the Grame and the Sibelius Academy for
support in writing this paper. They would especially like to thank Vesa
Norilo for his help in formalizing musical representation issues in
digital signal processing.
\end{acknowledgments} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%bibliography here
\bibliography{mike.bib,../../guido.bib}

\end{document}
