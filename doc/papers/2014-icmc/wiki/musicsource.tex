% -----------------------------------------------
% Template for ICMC SMC 2014
% adapted and corrected from the template for SMC 2013,  which was adapted from that of  SMC 2012, which was adapted from that of SMC 2011
% -----------------------------------------------

\documentclass{article}
\usepackage{icmcsmc2014}
\usepackage{times}
\usepackage{ifpdf}
\usepackage[english]{babel}
%\usepackage{cite}

%%%%%%%%%%%%%%%%%%%%%%%% Some useful packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% See related documentation %%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{amsmath} % popular packages from Am. Math. Soc. Please use the 
%\usepackage{amssymb} % related math environments (split, subequation, cases,
%\usepackage{amsfonts}% multline, etc.)
%\usepackage{bm}      % Bold Math package, defines the command \bf{}
%\usepackage{paralist}% extended list environments
%%subfig.sty is the modern replacement for subfigure.sty. However, subfig.sty 
%%requires and automatically loads caption.sty which overrides class handling 
%%of captions. To prevent this problem, preload caption.sty with caption=false 
%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}


%user defined variables
\def\papertitle{Towards a Music-Source Wiki}
\def\firstauthor{Mike Solomon}
\def\secondauthor{Mika Kuuskankare}
\def\thirdauthor{Dominique Fober}
\def\fourthauthor{Vesa Norilo}

% adds the automatic
% Saves a lot of ouptut space in PDF... after conversion with the distiller
% Delete if you cannot get PS fonts working on your system.

% pdf-tex settings: detect automatically if run by latex or pdflatex
\newif\ifpdf
\ifx\pdfoutput\relax
\else
   \ifcase\pdfoutput
      \pdffalse
   \else
      \pdftrue
\fi

\ifpdf % compiling with pdflatex
  \usepackage[pdftex,
    pdftitle={\papertitle},
    pdfauthor={\firstauthor, \secondauthor, \thirdauthor},
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen; 
                     % especially useful if working with a big screen :-)
   ]{hyperref}
  %\pdfcompresslevel=9

  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are and their extensions so 
  %you won't have to specify these with every instance of \includegraphics
  \graphicspath{{./figures/}}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}

  \usepackage[figure,table]{hypcap}

\else % compiling with latex
  \usepackage[dvips,
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen
  ]{hyperref}  % hyperrefs are active in the pdf file after conversion

  \usepackage[dvips]{epsfig,graphicx}
  % declare the path(s) where your graphic files are and their extensions so 
  %you won't have to specify these with every instance of \includegraphics
  \graphicspath{{./figures/}}
  \DeclareGraphicsExtensions{.eps}

  \usepackage[figure,table]{hypcap}
\fi

%setup the hyperref package - make the links black without a surrounding frame
\hypersetup{
    colorlinks,%
    citecolor=black,%
    filecolor=black,%
    linkcolor=black,%
    urlcolor=black
}


% Title.
% ------
\title{\papertitle}

% Authors
% Please note that submissions are NOT anonymous, therefore 
% authors' names have to be VISIBLE in your manuscript. 
%
% Single address
% To use with only one author or several with the same address
% ---------------
%\oneauthor
%   {\firstauthor} {Affiliation1 \\ %
%     {\tt \href{mailto:author1@smcnetwork.org}{author1@smcnetwork.org}}}

%Two addresses
%--------------
% \twoauthors
%   {\firstauthor} {Affiliation1 \\ %
%     {\tt \href{mailto:author1@smcnetwork.org}{author1@smcnetwork.org}}}
%   {\secondauthor} {Affiliation2 \\ %
%     {\tt \href{mailto:author2@smcnetwork.org}{author2@smcnetwork.org}}}

% Four addresses
% --------------
 \threeauthors
   {\firstauthor} {Grame \\ %
     {\tt \href{mailto:mike@mikesolomon.org}{mike@mikesolomon.org}}}
   {\secondauthor} {Sibelius Academy \\ %
     {\tt \href{mailto:mkuuskan@siba.fi}{mkuuskan@siba.fi}}}
   {\thirdauthor} {Grame \\ %
     {\tt \href{mailto:fober@grame.fr}{fober@grame.fr}}}
%   {\fourthauthor} {Sibelius Academy \\ %
%     {\tt \href{mailto:vnorilo@gmail.com}{vnorilo@gmail.com}}}


% ***************************************** the document starts here ***************
\begin{document}
%
\capstartfalse
\maketitle
\capstarttrue
%
\begin{abstract}
The abstract should be placed at the top left column and should contain about 150–-200 words.
\end{abstract}
%

\section{Introduction}\label{sec:introduction}
The Music-Source Wiki (MSW) project unites the fields of computer science, software
engineering and music in order to solve longstanding problems about music’s
representation on a computer as well as its ability to be distributed across
multiple computers. To frame the problem, we consider the representation of
music in state-of-the-art real\-time and non-real\-time music notation
environments.

Realtime environments, such as MuseScore~\cite{musescore}, concentrate on
the direct manipulation of graphical objects such as sound, waveforms,
graphics and video, often using approximations of complex structures in
order to facilitate quick rendering. Non-real\-time score editors, such as
Lilypond~\cite{lilypond06}, allow for robust musical representations at the expense of
interactivity. We see this disparity of music representation in real\-time and
non-real\-time environments as a fundamental problem in the field. Rich music
representation and real\-time interactivity should not be a trade-off –
instead, the two should complement each other.

The hampering effects of this issue are easily seen when one looks at how
other fields have solved the real\-time/non-real\-time problem. Online text
editors, for example, allow people to develop documents in real\-time while
retaining a rich view of these documents. The same is true of photo editing
on mobile devices, where users can apply filters to their photos almost
instantly thanks to automatic uploads and downloads to and from central
servers. We imagine a world where the same is possible in music – where,
thanks to a robust theoretical framework for the representation of music
transmitted to powerful servers over the web, users can work with rich
representations of music in real\-time.

This paper offers a practical roadmap
of the MSW project. After surveying the
state-of-the-art and describing the objectives of the project,
it discusses the three major phases of research necessary
for the implementation of a music-source wiki: (1) the creation of a robust
music representation language; (2) the elaboration of open web
specifications for the transmission of this language; and (3) the
construction of a collaborative on-line music editing platform.
\section{State-of-the-art}\label{sec:state-of-the-art}

All computer-assisted music notation programs are based on languages for the
representation of music that are more or less exposed to users. While it is
difficult to know the nature of the representation in closed-source
paradigms, open-source editors use music representation languages based on a
wide range of assumptions about how notated music should be encoded. Certain
formats, such as MusicXML~\cite{good2001musicxml}, use the instrument as the fundamental unit,
ascribing events to instruments and qualities to events in a hierarchical
manner. The language of the SCORE program focuses more on the physical
placement of musical glyphs. Yet others, like the LilyPond~\cite{lilypond06} and
Guido~\cite{hoos98}
languages, provide human-readable formats where notes, articulations,
dynamics, and rhythms are specified by their names in a given language. Some
paradigms, like that of MuseScore, offer no user-accessible textual representation
of music, translating a user’s point-and-clicks into internal objects that
represent musical symbols.

At present, there are a large number of score editors for desktop computers.
The two de facto industry standard notation programs are Finale and
Sibelius. The most notable free software projects are LilyPond and
Guido. Both of these programs compile documents written in LATEX like
markup languages that are used to describe the contents of a musical score
in textual form. WYSIWYG interfaces for these programs, such as Denemo
(LilyPond) and GuidoEditor (Guido), provide a point-and-click interface that
is translated into markup language before being compiled. Additionally,
there are several lightweight notation editors, such as abc and Gscore, for
typesetting relatively simple notation. Finally, NoteAbility provides
another paradigm where the software functions like an advanced image editor
with music-notation specific functionalities.

Recently, web-viewable score editors have started to emerge. There are three
main online musical score editors: Noteflight, Melodus and Scorio.
Noteflight and Melodus seek to provide a full-featured music editing
platform online, similar to Google Documents’ role in the world of office
suites. Scorio is a hybrid tool that mixes rudimentary layout via a mobile
editing platform with publication-quality layout via JIT compilation through
LilyPond when possible. Several music tools, such as Sibelius, MuseScore,
Maestro, and Capriccio, offer online services where scores composed using
this software can be uploaded, browsed, and downloaded online. WebLily,
LilyBin, and OMET are all JIT compilation services that run the LilyPond
executable to compile uploaded code and return embedded SVG, canvas or PDF
visualizations depending on the tool. Lastly, scoreSVG is another
alternative based on the Scalable Vector Graphics, a language for describing
two-\-di\-men\-sion\-al vector graphics in XML.

The disparity between realtime and non-realtime performance is perhaps most
noticeable in music notation programs. Because line-breaking algorithms for
musical scores are $O(2^n)$ hard without using any predictive heuristics, the
addition of new measures and new instruments in realtime can quickly lead to
less graceful and/or more sluggish line breaking choices. Non-realtime
editors require a much longer compilation time for line breaks but almost
always achieve aesthetically satisfactory results.



\section{Objectives}\label{sec:objectives}
\section{Music representation}\label{sec:music-representation}
The project will start with a theoretical inquiry into the representation of
music, using multiple existing representational languages as starting points
to frame questions such as:
\begin{itemize}
\item Using Hoare's work on axiomatic approaches to
programming~\cite{hoare1969axiomatic} as a basis, what are the atomic units
with which musical sound, ideas, procedures and data can be represented?
\item In what ways can these units be combined to form
larger structures?
\item To what extent are these structures combinable and transmutable into
other exchange formats?
\end{itemize}

The methodology used to answer these questions will start with a survey of
existing music representations, resulting in the creation and publication of
a comprehensive literature review that covers: (1) major computer-music
encoding
formats~\cite{hoos98}~\cite{lilypond06}~\cite{good2001musicxml}~\cite{alvaro2010musicjson}~\cite{roland2002music},
(2) traditional representations and encodings of music,
including various notation systems~\cite{hultberg2000printed} and formalizations
of sound synthesis and treatment
methods~\cite{mason1953feedback}~\cite{foote1999visualizing},
and (3) theoretical texts on music representation, from
early theories like Rameau's treatises on figured bass~\cite{rameau:1722} to later works
like Schenker’s reductive analysis methods~\cite{schenker:1935}.

During this phase, special attention will be given to the transversality of
our music representation language.  Various phenomena, such as notation,
performance practice, musical algorithsm and processes, sound synthesis and
signal processing will all have to be articulated via a combination of
atomic elements in this music representation.  Furthermore, we will need to
elaborate structures that allow for the linking of these elements.
This idea is partially implemented in visual programming environments like Max/MSP, where notation
structures can drive digital signal processing and vice-versa. Our project
seeks to generalize this to multiple aspects of music representation, control and
computation. For example, links between notation and process can control choices regarding
real\-time versus non-real\-time execution so that computation is reactive with
respect to content.

From these observations, a music representation language will be elaborated
along the following theoretical guidelines: (1) the theory of
representational language creation \cite{wagner2002design}~\cite{shieber1984design},
(2) the theory of process and algorithm
formalization~\cite{salwicki1970formalized}, and
(3) the theory of transcribing and storing language via exchange
formats~\cite{qiu1999programming}~\cite{gruber1993translation}. The
results of this research will be published as a technical report, offering a
complete grammar and alphabet for music representation as well as rules for
building a vocabulary. Several case studies will show how the language can
encode important musical works and concepts.

\section{Web-music specification}\label{sec:web-music-specification}
After having formalized a music representation language, we will turn to the
objective of creating a web music specification that allows this language to be
expressed across multiple terminals interacting with a server via a cloud
architecture. The open web specifications used to transmit the codified format
of our abstract musical representation will be created using a methodology
similar to that created for the Guido web API~\cite{solomon:2014}.
In the Guido web API, a Representational State Transfer (REST) server architecture
style~\cite{Fielding00}~\cite{richardson2008restful} is used to translate an Application
Programming Interface (API) into Uniform Resource Identifiers (URIs) via a
set of mapping conventions.

The same process of translation will be used in the
creation of open web specifications for our abstract musical representation,
extending these specifications to describe musical sound and processes. To verify
the portability of these specifications, they will be parallelly
developed in several common web interchange formats (JSON, XML, URIs, etc.),
aiming to achieve the same representational elegance and simplicity in all
of these formats. The result of this research will be a published open
specification as well as a series of libraries in common web languages
(JavaScript, PHP, etc.) to facilitate exchange via these specifications. The
specification will be empirically validated via a series of regression tests that
verify the transferring of every element of the abstract musical
representation over the web and the effective encoding, decoding and
translation of these test results into several programming languages and
open standard formats.


\section{Collaborative music editing platform}\label{sec:collaborative-music-editing-platform}
\section{Conclusion}\label{sec:conclusion}
\begin{acknowledgments}
The authors would like to thank the Grame and the Sibelius Academy for
support in writing this paper.
\end{acknowledgments} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%bibliography here
\bibliography{mike.bib,../../guido.bib}

\end{document}
